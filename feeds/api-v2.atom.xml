<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>DEEP Open Catalog - api-v2</title><link href="https://marketplace.deep-hybrid-datacloud.eu/" rel="alternate"></link><link href="https://marketplace.deep-hybrid-datacloud.eu/feeds/api-v2.atom.xml" rel="self"></link><id>https://marketplace.deep-hybrid-datacloud.eu/</id><updated>2020-02-03T11:41:04+01:00</updated><entry><title>Train an audio classifier</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/train-an-audio-classifier.html" rel="alternate"></link><published>2019-09-01T00:00:00+02:00</published><updated>2020-02-03T11:41:04+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-09-01:/modules/train-an-audio-classifier.html</id><summary type="html">&lt;p&gt;Train your own audio classifier with your custom dataset. It comes also pretrained on the 527 AudioSet classes.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-audio-classification-tf/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-audio-classification-tf/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a plug-and-play tool to perform audio classification with Deep Learning.
It allows the user to classify their samples of audio as well as training their
own classifier for a custom problem.&lt;/p&gt;
&lt;p&gt;The classifier is currently pretrained on the 527 high-level classes from the
&lt;a href="https://research.google.com/audioset/"&gt;AudioSet&lt;/a&gt; dataset.&lt;/p&gt;
&lt;p&gt;The PREDICT method expects an audio file as input (or the url of a audio file) and will return a JSON with 
the top 5 predictions. Most audio file formats are supported (see &lt;a href="https://www.ffmpeg.org/"&gt;FFMPEG&lt;/a&gt; compatible formats).&lt;/p&gt;
&lt;p&gt;&lt;img class='fit', src='https://raw.githubusercontent.com/deephdc/DEEP-OC-audio-classification-tf/master/images/demo.png'/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Jort F. Gemmeke, Daniel P. W. Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R. Channing Moore, Manoj Plakal, Marvin Ritter,&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45857.pdf"&gt;'Audio set: An ontology and human-labeled dataset for audio events'&lt;/a&gt;, IEEE ICASSP, 2017.&lt;/p&gt;
&lt;p&gt;Qiuqiang Kong, Yong Xu, Wenwu Wang, Mark D. Plumbley,&lt;a href="https://arxiv.org/pdf/1711.00927.pdf"&gt;'Audio Set classification with attention model: A probabilistic perspective.'&lt;/a&gt; arXiv preprint arXiv:1711.00927 (2017).&lt;/p&gt;
&lt;p&gt;Changsong Yu, Karim Said Barsim, Qiuqiang Kong, Bin Yang ,&lt;a href="https://arxiv.org/pdf/1803.02353.pdf"&gt;'Multi-level Attention Model for Weakly Supervised Audio Classification.'&lt;/a&gt; arXiv preprint arXiv:1803.02353 (2018).&lt;/p&gt;
&lt;p&gt;S. Hershey, S. Chaudhuri, D. P. W. Ellis, J. F. Gemmeke, A. Jansen, R. C. Moore, M. Plakal, D. Platt, R. A. Saurous, B. Seybold et  al., &lt;a href="https://arxiv.org/pdf/1609.09430.pdf"&gt;'CNN architectures for large-scale audio classification,'&lt;/a&gt; arXiv preprint arXiv:1609.09430, 2016.&lt;/p&gt;</content><category term="tensorflow"></category></entry><entry><title>Body pose detection</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/body-pose-detection.html" rel="alternate"></link><published>2019-07-31T00:00:00+02:00</published><updated>2020-02-03T11:41:03+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-07-31:/modules/body-pose-detection.html</id><summary type="html">&lt;p&gt;Detect body poses in images.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-posenet-tf/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-posenet-tf/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a plug-and-play tool for real-time pose estimation using deep neural networks. The original model, weights, code, etc. was created by Google and can be found at https://github.com/tensorflow/tfjs-models/tree/master/posenet. &lt;/p&gt;
&lt;p&gt;PoseNet can be used to estimate either a single pose or multiple poses, meaning there is a version of the algorithm that can detect only one person in an image/video and another version that can detect multiple persons in an image/video. &lt;/p&gt;
&lt;p&gt;The PREDICT method expects an RGB image as input (or the url of an image) and returns as output the different body keypoints with the corresponding coordinates and the associated key score
&lt;img class='fit', src='https://raw.githubusercontent.com/deephdc/DEEP-OC-posenet-tf/master/images/posenet.png'/&gt;&lt;/p&gt;</content><category term="tensorflow"></category></entry><entry><title>DEEP OC Massive Online Data Streams</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/deep-oc-massive-online-data-streams.html" rel="alternate"></link><published>2019-02-19T00:00:00+01:00</published><updated>2020-02-03T11:40:43+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-02-19:/modules/deep-oc-massive-online-data-streams.html</id><summary type="html">&lt;p&gt;Massive Online Data Streams analysis&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-mods/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-mods/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This use case analyzes online data streams in order to generate alerts with time-bounded constrains and in real-time.
The main study is focused on building additional intelligent module using NN and DL techniques
in co-function with underlying Intrusion Detection Systems (IDS) supervising traffic networks of compute centers.
Preserving old data for historical purposes, security analysts will be able to supervise generated alerts
and to enhance cyber security [1, 2] for such centers when large IT infrastructures and devices
products a huge amount of data streaming continuously and dynamically.&lt;/p&gt;
&lt;p&gt;The principle of the solution is proactive time-series prediction [5] adopting NNs as well as DL to build
prediction models capable to predict next step(s) in near future based on given current and past steps.
The discrepancy between the prediction and the reality gives an indication of anomaly (i.e. anomaly detection).&lt;/p&gt;
&lt;p&gt;The challenge of the solution is it aims to scalable edge technologies [4] to support
extensive data analysis and modelling as well as to improve the cyber-resilience by adopting an heuristic approach,
that combines misuse detection in real-time with the building intelligence module using NN and DL.&lt;/p&gt;
&lt;p&gt;Current modelling approach using DL techniques [3]:
LSTM (vanilla, stacked, bidirectional, seq2seq encoder/decoder), GRU, CNN, and MLP&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1]: Bhattacharyya, D.K. and Kalita, J.K., 2013. Network anomaly detection: A machine learning perspective. Chapman and Hall/CRC.&lt;/p&gt;
&lt;p&gt;[2]: Dua, S. and Du, X., 2016. Data mining and machine learning in cybersecurity. Auerbach Publications.&lt;/p&gt;
&lt;p&gt;[3]: Yann LeCun, Yoshua Bengio, and Geofrey Hinton. &lt;a href="https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf"&gt;Deep learning&lt;/a&gt;. Nature, 521(7553):436-444, may 2015.&lt;/p&gt;
&lt;p&gt;[4]: Nguyen, G., Nguyen, B.M., Tran, D. and Hluchy, L., 2018. A heuristics approach to mine behavioural data logs in mobile malware detection system. Data &amp;amp; Knowledge Engineering, 115, pp.129-151.&lt;/p&gt;
&lt;p&gt;[5]: Tran, N., Nguyen, T., Nguyen, B.M. and Nguyen, G., 2018. A Multivariate Fuzzy Time Series Resource Forecast Model for Clouds using LSTM and Data Correlation Analysis. Procedia Computer Science, 126, pp.636-645.&lt;/p&gt;</content><category term="services"></category></entry><entry><title>Conus species classifier</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/conus-species-classifier.html" rel="alternate"></link><published>2019-01-01T00:00:00+01:00</published><updated>2020-02-03T11:40:50+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-01-01:/modules/conus-species-classifier.html</id><summary type="html">&lt;p&gt;Classify conus images among 70 species.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-conus-classification-tf/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-conus-classification-tf/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Citizen science has become a powerful force for scientific inquiry, providing researchers with access to a vast array
of data points while connecting non scientists to the real process of science. This citizen-researcher relationship
creates a very interesting synergy, allowing for the creation, execution, and analysis of research projects.
With this in mind, a Convolutional Neural Network has been trained to identify conus marine snails at species
level [1] in collaboration with the &lt;a href="http://www.mncn.csic.es/"&gt;Natural Science Museum of Madrid&lt;/a&gt;. The taxonomy
of these snails has changed significantly several times during recent years and the introduction of Deep Learning
techniques allowing to classify them is a very valuable tool for the experts.&lt;/p&gt;
&lt;p&gt;This Docker container contains a trained Convolutional Neural network optimized for conus identification using
images. The architecture used is an Xception [2] network using Keras on top of Tensorflow.&lt;/p&gt;
&lt;p&gt;The PREDICT method expects an RGB image as input (or the url of an RGB image) and will return a JSON with 
the top 5 predictions.&lt;/p&gt;
&lt;p&gt;The training dataset has been provided by the &lt;a href="http://www.mncn.csic.es/"&gt;Natural Science Museum of Madrid&lt;/a&gt; and
it consists on a dataset containing images of 68 species of conus covering three different regions: the Panamic
region; the South African region; and the Western Atlantic and Mediterranean region.&lt;/p&gt;
&lt;p&gt;&lt;img class='fit', src='https://raw.githubusercontent.com/deephdc/DEEP-OC-conus-classification-tf/master/images/conus.png'/&gt;&lt;/p&gt;
&lt;p&gt;This service is based in the &lt;a href="./deep-oc-image-classification-tensorflow.html"&gt;Image Classification with Tensorflow&lt;/a&gt; model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1]: Puillandre, N.; Duda, T.F.; Meyer, C.; Olivera, B.M.; Bouchet, P. (2014). &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4541476/"&gt;One, four or 100 genera? A new classification of the cone snails&lt;/a&gt;. Journal of Molluscan Studies. 81 (1): 1-23.&lt;/p&gt;
&lt;p&gt;[2]: Chollet, Francois. &lt;a href="https://arxiv.org/abs/1610.02357"&gt;Xception: Deep learning with depthwise separable convolutions&lt;/a&gt; arXiv preprint (2017): 1610-02357.&lt;/p&gt;</content><category term="tensorflow"></category></entry><entry><title>Phytoplankton species classifier</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/phytoplankton-species-classifier.html" rel="alternate"></link><published>2019-01-01T00:00:00+01:00</published><updated>2020-02-03T11:40:52+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-01-01:/modules/phytoplankton-species-classifier.html</id><summary type="html">&lt;p&gt;Classify phytoplankton images among 60 classes.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-phytoplankton-classification-tf/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-phytoplankton-classification-tf/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Citizen science has become a powerful force for scientific inquiry, providing researchers with access to a vast array of
data points while connecting non scientists to the real process of science. This citizen-researcher relationship
creates a very interesting synergy, allowing for the creation, execution, and analysis of research projects. 
With this in mind, a Convolutional Neural Network has been trained to identify phytoplankton in collaboration
with the &lt;a href="http://www.vliz.be/"&gt;Vlaams Instituut voor de Zee&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This Docker container contains a trained Convolutional Neural network optimized for phytoplankton identification using
images. The architecture used is an Xception [1] network using Keras on top of Tensorflow.&lt;/p&gt;
&lt;p&gt;The PREDICT method expects an RGB image as input (or the url of an RGB image) and will return a JSON with 
the top 5 predictions.&lt;/p&gt;
&lt;p&gt;As training dataset we have used a collection of images from the &lt;a href="http://www.vliz.be/"&gt;Vlaams Instituut voor de Zee&lt;/a&gt;
which consists of around 650K images from 60 classes of phytoplankton.&lt;/p&gt;
&lt;p&gt;&lt;img class='fit', src='https://raw.githubusercontent.com/deephdc/DEEP-OC-phytoplankton-classification-tf/master/images/phytoplankton.png'/&gt;&lt;/p&gt;
&lt;p&gt;This service is based in the &lt;a href="./deep-oc-image-classification-tensorflow.html"&gt;Image Classification with Tensorflow&lt;/a&gt; model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1]: Chollet, Francois. &lt;a href="https://arxiv.org/abs/1610.02357"&gt;Xception: Deep learning with depthwise separable convolutions&lt;/a&gt; arXiv preprint (2017): 1610-02357.&lt;/p&gt;</content><category term="tensorflow"></category></entry><entry><title>Plants species classifier</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/plants-species-classifier.html" rel="alternate"></link><published>2019-01-01T00:00:00+01:00</published><updated>2020-02-03T11:40:48+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-01-01:/modules/plants-species-classifier.html</id><summary type="html">&lt;p&gt;Classify plant images among 10K species from the iNaturalist dataset.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-plants-classification-tf/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-plants-classification-tf/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The deep learning revolution has brought significant advances in a number of fields [1], primarily linked to
image and speech recognition. The standardization of image classification tasks like the &lt;a href="http://www.image-net.org/challenges/LSVRC/"&gt;ImageNet Large Scale
Visual Recognition Challenge&lt;/a&gt; [2] has resulted in a reliable way to
compare top performing architectures.&lt;/p&gt;
&lt;p&gt;The use of deep learning for plant classification is not novel [3, 4] but has mainly focused in leaves and has
been restricted to a limited amount of species, therefore making it of limited use for large-scale biodiversity
monitoring purposes.&lt;/p&gt;
&lt;p&gt;This Docker container contains a trained Convolutional Neural network optimized for plant identification using
images. The architecture used is an Xception [5] network using Keras on top of Tensorflow. A detailed article
about this network and the results obtained with it can be found in [6].&lt;/p&gt;
&lt;p&gt;The PREDICT method expects an RGB image as input (or the url of an RGB image) and will return a JSON with 
the top 5 predictions.&lt;/p&gt;
&lt;p&gt;The original training dataset was the great collection of images which are available in &lt;a href="https://identify.plantnet.org/"&gt;PlantNet&lt;/a&gt; under a 
Creative-Common AttributionShareAlike 2.0 license. It consists of around 250K images belonging to more than 6K
plant species of Western Europe. These species are distributed in 1500 genera and 200 families.&lt;/p&gt;
&lt;p&gt;A new iteration of the application has been trained using plant images from &lt;a href="https://www.inaturalist.org/"&gt;iNaturalist&lt;/a&gt;.
This dataset has around 4.4M observations with 7M images from 58K worldwide species.
We have restricted our training to the 10K most popular species.&lt;/p&gt;
&lt;p&gt;&lt;img class='fit', src='https://raw.githubusercontent.com/deephdc/DEEP-OC-plants-classification-tf/master/images/plants.png'/&gt;&lt;/p&gt;
&lt;p&gt;This service is based in the &lt;a href="./deep-oc-image-classification-tensorflow.html"&gt;Image Classification with Tensorflow&lt;/a&gt; model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1]: Yann LeCun, Yoshua Bengio, and Geofrey Hinton. &lt;a href="https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf"&gt;Deep learning&lt;/a&gt;. Nature, 521(7553):436-444, May 2015.&lt;/p&gt;
&lt;p&gt;[2]: Olga Russakovsky et al. &lt;a href="https://arxiv.org/abs/1409.0575"&gt;ImageNet Large Scale Visual Recognition Challenge&lt;/a&gt;. International Journal of Computer Vision (IJCV), 115(3):211-252, 2015.&lt;/p&gt;
&lt;p&gt;[3]: Sue Han Lee, Chee Seng Chan, Paul Wilkin, and Paolo Remagnino. &lt;a href="https://arxiv.org/abs/1506.08425"&gt;Deep-plant: Plant identification with convolutional neural networks&lt;/a&gt;, 2015.&lt;/p&gt;
&lt;p&gt;[4]: Mads Dyrmann, Henrik Karstoft, and Henrik Skov Midtiby. &lt;a href="https://www.sciencedirect.com/science/article/pii/S1537511016301465"&gt;Plant species classification using deep convolutional neural network.&lt;/a&gt; Biosystems Engineering, 151:72-80, 2016.&lt;/p&gt;
&lt;p&gt;[5]: Chollet, Francois. &lt;a href="https://arxiv.org/abs/1610.02357"&gt;Xception: Deep learning with depthwise separable convolutions&lt;/a&gt; arXiv preprint (2017): 1610-02357.&lt;/p&gt;
&lt;p&gt;[6]: Heredia, Ignacio. &lt;a href="https://arxiv.org/abs/1706.03736"&gt;Large-scale plant classification with deep neural networks.&lt;/a&gt; Proceedings of the Computing Frontiers Conference. ACM, 2017.&lt;/p&gt;</content><category term="tensorflow"></category></entry><entry><title>Seed species classifier</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/seed-species-classifier.html" rel="alternate"></link><published>2019-01-01T00:00:00+01:00</published><updated>2020-02-03T11:40:56+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-01-01:/modules/seed-species-classifier.html</id><summary type="html">&lt;p&gt;Classify seeds images among 700K species.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-seeds-classification-tf/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-seeds-classification-tf/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Citizen science has become a powerful force for scientific inquiry, providing researchers with access to a vast array of
data points while connecting non scientists to the real process of science. This citizen-researcher relationship
creates a very interesting synergy, allowing for the creation, execution, and analysis of research projects. 
With this in mind, a Convolutional Neural Network has been trained to identify seed images in collaboration 
with &lt;a href="http://www.rjb.csic.es"&gt;Spanish Royal Botanical Garden&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This Docker container contains a trained Convolutional Neural network optimized for seeds identification using
images. The architecture used is an Xception [1] network using Keras on top of Tensorflow.&lt;/p&gt;
&lt;p&gt;The PREDICT method expects an RGB image as input (or the url of an RGB image) and will return a JSON with 
the top 5 predictions.&lt;/p&gt;
&lt;p&gt;As training dataset we have used a collection of images from the &lt;a href="http://www.rjb.csic.es"&gt;Spanish Royal Botanical Garden&lt;/a&gt;
which consists of around 28K images from 743 species and 493 genera.&lt;/p&gt;
&lt;p&gt;&lt;img class='fit', src='https://raw.githubusercontent.com/deephdc/DEEP-OC-seeds-classification-tf/master/images/seeds.png'/&gt;&lt;/p&gt;
&lt;p&gt;This service is based in the &lt;a href="./deep-oc-image-classification-tensorflow.html"&gt;Image Classification with Tensorflow&lt;/a&gt; model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1]: Chollet, Francois. &lt;a href="https://arxiv.org/abs/1610.02357"&gt;Xception: Deep learning with depthwise separable convolutions&lt;/a&gt; arXiv preprint (2017): 1610-02357.&lt;/p&gt;</content><category term="tensorflow"></category></entry><entry><title>Train an image classifier</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/train-an-image-classifier.html" rel="alternate"></link><published>2019-01-01T00:00:00+01:00</published><updated>2020-02-03T11:40:46+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-01-01:/modules/train-an-image-classifier.html</id><summary type="html">&lt;p&gt;Train your own image classifier with your custom dataset. It comes also pretrained on the 1K ImageNet classes.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-image-classification-tf/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-image-classification-tf/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The deep learning revolution has brought significant advances in a number of fields [1], primarily linked to
image and speech recognition. The standardization of image classification tasks like the &lt;a href="http://www.image-net.org/challenges/LSVRC/"&gt;ImageNet Large Scale
Visual Recognition Challenge&lt;/a&gt; [2] has resulted in a reliable way to
compare top performing architectures.&lt;/p&gt;
&lt;p&gt;This Docker container contains the tools to train an image classifier on your personal dataset. It is a highly
customizable tool  that let's you choose between tens of different &lt;a href="https://github.com/keras-team/keras-applications"&gt;top performing architectures&lt;/a&gt;
and training parameters.&lt;/p&gt;
&lt;p&gt;The container also comes with a pretrained general-purpose image classifier trained on ImageNet.&lt;/p&gt;
&lt;p&gt;The PREDICT method expects an RGB image as input (or the url of an RGB image) and will return a JSON with 
the top 5 predictions.&lt;/p&gt;
&lt;p&gt;&lt;img class='fit', src='https://raw.githubusercontent.com/deephdc/DEEP-OC-image-classification-tf/master/images/imagenet.png'/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1]: Yann LeCun, Yoshua Bengio, and Geofrey Hinton. &lt;a href="https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf"&gt;Deep learning&lt;/a&gt;. Nature, 521(7553):436-444, May 2015.&lt;/p&gt;
&lt;p&gt;[2]: Olga Russakovsky et al. &lt;a href="https://arxiv.org/abs/1409.0575"&gt;ImageNet Large Scale Visual Recognition Challenge&lt;/a&gt;. International Journal of Computer Vision (IJCV), 115(3):211-252, 2015.&lt;/p&gt;</content><category term="tensorflow"></category></entry></feed>