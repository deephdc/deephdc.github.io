<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>DEEP Open Catalog - cnn</title><link href="https://marketplace.deep-hybrid-datacloud.eu/" rel="alternate"></link><link href="https://marketplace.deep-hybrid-datacloud.eu/feeds/cnn.atom.xml" rel="self"></link><id>https://marketplace.deep-hybrid-datacloud.eu/</id><updated>2020-05-27T17:28:53+02:00</updated><entry><title>TF Benchmarks</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/deep-oc-benchmarks-cnn.html" rel="alternate"></link><published>2019-12-19T00:00:00+01:00</published><updated>2020-05-27T17:28:53+02:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-12-19:/modules/deep-oc-benchmarks-cnn.html</id><summary type="html">&lt;p&gt;tf_cnn_benchmarks accessed via DEEPaaS API&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-benchmarks_cnn/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-benchmarks_cnn/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks"&gt;tf_cnn_benchmarks&lt;/a&gt;
from TensorFlow team accessed via &lt;a href="https://github.com/indigo-dc/DEEPaaS"&gt;DEEPaaS API&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;tf_cnn_benchmarks contains implementations of several popular convolutional models 
(e.g. Googlenet, Inception, Overfeat, Resnet, VGG), 
and is designed to be as fast as possible. tf_cnn_benchmarks supports running on a single machine 
on a single GPU and multiple GPUs
(please, note that running in distributed mode across multiple hosts is not supported by these Docker images).
See the &lt;a href="https://www.tensorflow.org/performance/performance_models"&gt;High-Performance models guide&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1] TF CNN Benchmarks: &lt;a href=https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks&gt;https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks&lt;/a&gt;&lt;/p&gt;</content><category term="docker"></category></entry><entry><title>semseg_vaihingen</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/deep-oc-semseg-vaihingen.html" rel="alternate"></link><published>2019-09-30T00:00:00+02:00</published><updated>2020-05-27T17:28:50+02:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-09-30:/modules/deep-oc-semseg-vaihingen.html</id><summary type="html">&lt;p&gt;2D semantic segmentation on the Vaihingen dataset&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-semseg_vaihingen/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-semseg_vaihingen/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Example application for ISPRS 2D Semantic Labeling Contest [1]:&lt;/p&gt;
&lt;p&gt;2D semantic segmentation (Vaihingen dataset [2]) that assigns labels to multiple object categories.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Vaihingen dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;33 patches of different sizes with 9 cm spatial resolution&lt;/li&gt;
&lt;li&gt;Manually classified into six land cover classes:&lt;/li&gt;
&lt;li&gt;Impervious surfaces, Building, Low vegetation, Tree, Clutter/background&lt;/li&gt;
&lt;li&gt;The groundtruth is provided for only 16 patches&lt;/li&gt;
&lt;li&gt;For the remaining scenes it is unreleased and used for evaluation of submitted results&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;N.B.:&lt;/strong&gt; pre-trained weights can be found &lt;a href=https://nc.deep-hybrid-datacloud.eu/s/eTqJexZ5PcBxXR6&gt;here&lt;/a&gt; (unzip before use!)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=http://www2.isprs.org/commissions/comm3/wg4/semantic-labeling.html&gt;http://www2.isprs.org/commissions/comm3/wg4/semantic-labeling.html&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;[2] M. Cramer: The DGPF-Test on Digital Airborne Camera Evaluation Overview and Test Design, 
PFG Photogrammetrie, Fernerkundung, Geoinformation, vol. 2010, no. 2, pp. 73-82, 2010.&lt;/p&gt;</content><category term="tensorflow"></category></entry><entry><title>Dogs breed detector</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/deep-oc-dogs-breed-det.html" rel="alternate"></link><published>2018-11-18T00:00:00+01:00</published><updated>2020-05-27T17:28:31+02:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2018-11-18:/modules/deep-oc-dogs-breed-det.html</id><summary type="html">&lt;p&gt;Identify a dogs breed on the image (133 known breeds)&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-dogs_breed_det/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-dogs_breed_det/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The application applies Transfer learning for dog's breed identification, which is implemented by the means of Tensorflow and Keras:&lt;/p&gt;
&lt;p&gt;From a pre-trained CNN model (VGG16 | VGG19 | Resnet50 | InceptionV3 [1]) the last layer is removed,
then new Fully Connected (FC) layers are added, which are trained on the dog's dataset.&lt;/p&gt;
&lt;p&gt;The original dataset ([2]) consists of 8351 dog's images for 133 breeds divided into: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;training set (6680 pictures)&lt;/li&gt;
&lt;li&gt;validation set (835)&lt;/li&gt;
&lt;li&gt;test set (836)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and amounts for &lt;strong&gt;1080 MB&lt;/strong&gt; in zipped format (see the dataset link).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;N.B.:&lt;/strong&gt; pre-trained weights can be found &lt;a href=https://nc.deep-hybrid-datacloud.eu/s/D7DLWcDsRoQmRMN&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1] CNN articles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VGG: Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition.
 CoRR abs/1409.1556 (2014); http://arxiv.org/abs/1409.1556&lt;/li&gt;
&lt;li&gt;Resnet: He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun: Deep residual learning for image recognition. 
In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778. 2016. https://arxiv.org/abs/1512.03385&lt;/li&gt;
&lt;li&gt;InceptionV3: Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, Zbigniew Wojna; The IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), 2016, pp. 2818-2826. https://arxiv.org/abs/1512.00567&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[2] Dogs dataset: &lt;a href=https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip&gt;
https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip&lt;/a&gt;&lt;/p&gt;</content><category term="tensorflow"></category></entry></feed>