<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>DEEP Open Catalog - cnn</title><link href="https://marketplace.deep-hybrid-datacloud.eu/" rel="alternate"></link><link href="https://marketplace.deep-hybrid-datacloud.eu/feeds/cnn.atom.xml" rel="self"></link><id>https://marketplace.deep-hybrid-datacloud.eu/</id><updated>2019-12-04T17:21:53+01:00</updated><entry><title>semseg_vaihingen</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/semseg_vaihingen.html" rel="alternate"></link><published>2019-09-30T00:00:00+02:00</published><updated>2019-12-04T17:21:53+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2019-09-30:/modules/semseg_vaihingen.html</id><summary type="html">&lt;p&gt;2D semantic segmentation on the Vaihingen dataset&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-semseg_vaihingen/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-semseg_vaihingen/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Example application for ISPRS 2D Semantic Labeling Contest [1]:&lt;/p&gt;
&lt;p&gt;2D semantic segmentation (Vaihingen dataset [2]) that assigns labels to multiple object categories.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Vaihingen dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;33 patches of different sizes with 9 cm spatial resolution&lt;/li&gt;
&lt;li&gt;Manually classified into six land cover classes:&lt;/li&gt;
&lt;li&gt;Impervious surfaces, Building, Low vegetation, Tree, Clutter/background&lt;/li&gt;
&lt;li&gt;The groundtruth is provided for only 16 patches&lt;/li&gt;
&lt;li&gt;For the remaining scenes it is unreleased and used for evaluation of submitted results&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;N.B.:&lt;/strong&gt; pre-trained weights can be found &lt;a href=https://nc.deep-hybrid-datacloud.eu/s/eTqJexZ5PcBxXR6&gt;here&lt;/a&gt; (unzip before use!)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=http://www2.isprs.org/commissions/comm3/wg4/semantic-labeling.html&gt;http://www2.isprs.org/commissions/comm3/wg4/semantic-labeling.html&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;[2] M. Cramer: The DGPF-Test on Digital Airborne Camera Evaluation Overview and Test Design, 
PFG Photogrammetrie, Fernerkundung, Geoinformation, vol. 2010, no. 2, pp. 73-82, 2010.&lt;/p&gt;</content><category term="tensorflow"></category></entry><entry><title>DEEP OC Dogs breed detection</title><link href="https://marketplace.deep-hybrid-datacloud.eu/modules/deep-oc-dogs-breed-detection.html" rel="alternate"></link><published>2018-11-18T00:00:00+01:00</published><updated>2019-12-04T17:21:05+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2018-11-18:/modules/deep-oc-dogs-breed-detection.html</id><summary type="html">&lt;p&gt;A test application to identify Dog's breed as an example for DEEPaaS API.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu/job/Pipeline-as-code/job/DEEP-OC-org/job/DEEP-OC-dogs_breed_det/job/master"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/DEEP-OC-dogs_breed_det/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This test application applies Transfer learning for dog's breed identification,
which is implemented by means of Tensorflow and Keras: &lt;/p&gt;
&lt;p&gt;From a pre-trained CNN model 
(VGG16 | VGG19 | Resnet50 | InceptionV3) &lt;a href=""&gt;1&lt;/a&gt; the last layer is removed, 
then two new Fully Connected (FC) layers are added, which are trained on the dog's dataset. &lt;/p&gt;
&lt;p&gt;The original dataset [2] consists of 8351 dog's images for 133 breeds divided into 
training set (6680 pictures), validation set (835), and test set (836), and amounts for 1080 MB in zipped format.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;VGG: Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. CoRR abs/1409.1556 (2014); http://arxiv.org/abs/1409.1556 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Resnet: He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun: Deep residual learning for image recognition. 
In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778. 2016. https://arxiv.org/abs/1512.03385 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;InceptionV3: Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, Zbigniew Wojna; The IEEE Conference on Computer Vision 
and Pattern Recognition (CVPR), 2016, pp. 2818-2826. https://arxiv.org/abs/1512.00567 &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[2]: Dogs dataset: https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip&lt;/p&gt;</content><category term="docker"></category></entry></feed>